What if we used mutation, selection, rational engineering, and ML where appropriate, for guiding a population of small mammals (perhaps mice or rats) such that we select for mammalian brains where the big questions of neuroscience can be more easily investigated?

For example, to some extent previous (old) theory around "brain regions" turned out to be somewhat wrong. However, if it was true it would have been highly convenient for investigative purposes. It does not seem implausible to assay localization of certain functions and select for members of a population that tend to localize certain functions to a design of our choice, over time. At least, to a greater extent than some areas are already dedicated to certain functions.

For example, some neuroscientists subscribe to a holographic theory of memory engram storage. It may even be true! I don't know. But if it is true, it certainly complicates the mission of memory engram research. We could instead nudge a population towards a biology that is less "holographic" and where memory is much more physically localized into a specific, visually identifiable or otherwise identifiable region of the brain that we could then subject to usual research techniques.

Other researchers have suggested that besides synaptic weights being important for long-term data storage in the human brain, there might be other molecular configurations that strongly matter, such as intracellular RNA, extracellular RNA, receptor densities, extracellular matrix configurations, etc. All of the options sound quite tiring, and it could be the case that brains use all of those modalities, or some subset. Instead, it would be more convenient to nudge towards a trend of using one of the specific modalities instead of all of them.

Substantially smaller brains that retain most of the observed functionality and behavior may be useful for research purposes. Instead of growing organoids into larger objects, we should consider going in the other direction (working brains -> smaller working brains that are easier to examine under microscopy). Oh also, smaller brains could refer to mass, volume, neuron count, or synapse count, which would improve whole-brain connectomics scale issues.

What if we evolved biological brains to be maximally understandable? Unfortunately the brain has many thousands or millions of confounders. Removing (for example) nonlocalization on its own may be significantly useful even if other confounders remain. I suppose it is a question of estimating potential utility, and then estimating the cost of achieving that potential utility, both of which are unknowns.

We should generally select to minimize the total "confoundance". Even a reduction from 2^90 to 2^60 is enough, in some fields of study, to render a problem amenable to bruteforce computational solving. It may be possible to empirically investigate this sort of "confounding factor reduction" idea in a computational-only way to see what the parameters, limits and bounds need to be in order for 'dimensionality reduction' to be feasible. After that, the next step would be to test it by picking a simpler biological problem (where we already know the answers) to physically try the technique. Venter's synthetic minimal genome is not the only plausible synthetic minimal genome but it is at least one (actually three) that we presently have available. Other biological problems are also worth considering, like simpler multi-enzyme systems like for DNA replication, replication fork management, etc.

Understanding the nature of human biological memory may not be necessary in order to evolve a biological brain that is more amenable to our current scientific techniques of investigation.

It could be helpful to use the concepts of physical reservoire computing when thinking about the human brain. In RC we do not necessarily attribute computation to just synaptic weights but also to many kinds of plausible phenomena including atom-atom interactions, protein-protein, gradients, neurohormone signaling, mRNA expression, extracellular matrix structural topology, ECM holes, ECM density, electrical activity, etc. Michael Levin made a related point recently about this <https://gnusha.org/logs/2025-06-18.log>:

```
10:44 < kanzure> from levin's "agentila memory" article: https://www.mdpi.com/1099-4300/26/6/481 
10:44 < kanzure> ".. if engrams are not in the synaptic structures [217], where are they? My current hypothesis, driven by the above multi-scale perspective [218], is that there is no single substrate for memory[49]. Every component of the system, including but not limited to those that bubble up to conscious recollections, could be using everything in its environment as an interpretable scratchpad[50]. The deep levels of biological structure and dynamics offer an incredibly high-dimensional physical reservoir [223,224,225,226] (referred to as the senome in [19,227]) that can be exploited for memory remapping[51]. In this view, neuronal networks are not so much used for holding memory as they are for learning to interpret the engrams embodied by subcellular components [34,35]."
10:45 < kanzure> not sure why he felt the need to invoke subcellular memory engram embodiment (isn't it sufficient to say high-dimensional physical system if he belives in a "senome")?)
10:52 < kanzure> well maybe it's because he has some evidence of at least one physical memory engram substrate (and it seems to be a likely molecular object, like RNA) from his references 111 through 122 showing memory transfer to different somatic selflets (other animals) (mostly from the 1960s) by e.g. brain tissue extracts, RNA, or other objects.
10:54 < kanzure> still, biological neuronal networks can still have other roles like learning to interpret or utilize other high-dimensional physical reservoires besides just subcellular molecular memory objects and i'm not sure if possible to rule that out as a modality.
10:58 < kanzure> for the purposes of memory preservation, computational read/write of memory, uploading, or similar purposes, it would be very convenient if there is at least one physical substrate of memory that is accessible to our technologies such as DNA sequencing, RNA sequencing, electron beam scanning of the connectome, DNA memory tape readout, or another practicable technique.
10:59 < kanzure> if there really are multiple competing substrate options for biological cognitive memory storage, then we ought to try artificial selection to nudge towards a single modality; i have previously commented on the idea of artificial selection to nudge towards physical memory consolidation in a specific location in the brain instead of whole-brain memory storage or sparse storage, a related concept.
11:00 < kanzure> nudging towards single memory object type (of our choice) and a single centralized location is useful for goals like storage, preservation, memory read/write, and amenable to lesioning proofs.
11:02 < kanzure> i should add physical extraction to that list. physical extraction is useful because it lets us poke at things in a way that "here is a big brain have fun not being able to orchestrate it to run your studies" does not.
...
23:09 < fenn> DNA ticker tape readout could also be a record of activations, is that a memory?
23:09 < fenn> redundant distributed systems are very fault tolerant
23:10 < fenn> i'd rather have a fault tolerant brain than an easily readable one
23:10 < fenn> also i don't think it will be necessary in practice
23:12 < fenn> we should be able to distill memories by recording the process of recall, and training another network to predict that activation pattern
23:12 < fenn> then the other network can be designed to be easy to read, or it could be the final product
23:14 < fenn> is a distilled network 'the same' as the original? no, but it can be a damned good copy
```

hod lipson had an interesting paper about a "<a href="https://direct.mit.edu/isal/proceedings-pdf/alife2018/30/234/1904922/isal_a_00049.pdf">neural network quine</a>" that learns its own weights and can predict or generate its weights, which can be used as a method of self-reproduction. There is some information loss and tradeoff of course. See also "<a href="https://arxiv.org/abs/1801.01952">Generating neural networks with neural networks"</a>.

<a href="https://gnusha.org/logs/2025-02-25.log">logref</a> for following:

```
04:07 < hprmbridge> kanzure> if you can talk to a potato, then why not a dead brain?
04:07 < fenn> because the mechanism of information storage is different
04:08 < hprmbridge> kanzure> the mechanism is unknown.
04:08 < fenn> the mechanism is synaptic receptor density for various neurotransmitters
04:08 < fenn> don't make me re-read the potato paper
04:09 < hprmbridge> kanzure> what is needed is a way to convert into a more legible format, chemically, without long term DNA engineering required
04:09 < fenn> "long term DNA engineering"?
04:10 < hprmbridge> kanzure> what was wrong with russell Hanson's gold nanoparticle aptamers for neurotransmitter receptors? someone was complaining about microCT  max x-ray resolution?
04:10 < fenn> express barcodes in each cell along with synaptic receptor proteins, export most of that DNA into the synaptic cleft along with some ligase to splice it onto the neighboring cell barcode DNA
04:10 < hprmbridge> kanzure> yeah like delivering genetic updates to every neuron
04:11 < fenn> without gene therapy i suppose
04:12 < hprmbridge> kanzure> chemical transformation could be more efficient and near term accessible compared to "hope we can deliver genetics to every single neuron" other than embryo engineering
04:13 < hprmbridge> kanzure> there are several competing theories for human biological memory format. it's not just connectome and receptor weights...
04:14 < hprmbridge> kanzure> https://gershmanlab.com/pubs/memory_synthesis.pdf
04:14 < fenn> ok so fortunately we can use random neuron ID sequences, so you could plausibly have a nanoparticle-surface-attached replicating random DNA as the barcode, which then gets released into the cleft to combine with the neighboring nanoparticles
04:15 < fenn> the only difference here is that it's replicating outside of the cell instead of inside. i don't think this makes it easier
04:16 < hprmbridge> kanzure> human brains should be replaced with auto generative neural networks that can accurately predict their own weights, so that we don't get into this mess in the future
04:17 < fenn> there have been no randomized double blind placebo controlled studies of parachutes
04:18 < fenn> is there any serious alternative theory of memory storage besides synapses?
04:19 < fenn> do we care about epigenetics and mRNA in neurons?
04:20 < fenn> it doesn't seem fast enough to account for the kinds of behavior we care about
04:20 < fenn> like wow circadian rhythms exist
04:25 < fenn> if the alternative theory is in that paper, i'm not seeing it
04:25 < hprmbridge> kanzure> go go gadget LLM summarizer.
04:27 < fenn> .kagi list the alternative theories of memory formation in https://gershmanlab.com/pubs/memory_synthesis.pdf
04:27 < gptpaste> ​null# Tue Feb 25 12:27:15 PM UTC 2025 - URL: list - Q: the alternative theories of memory formation in https://gershmanlab.com/pubs/memory_synthesis.pdf - https://gist.github.com/Epivalent/02fd9fabc66f41969e5aeef95a966e27/raw
04:27 < fenn> .kagi https://gershmanlab.com/pubs/memory_synthesis.pdf list the alternative theories of memory formation
04:27 < gptpaste> ​"Alternative theories of memory formation challenge the traditional view that memories are primarily stored through synaptic modifications. Here are some notable alternative theories:1. **Intracellular Molecular Substrates**:   - This theory posits that memories are encoded in molecules within the cell, rather than at the synapse. The specific nature of these molecular subst - https://gist.github.com/Epivalent/5a292b1c874cef76a597842a4e9e99ec/raw
04:29 < fenn> did it even read the paper
04:34 < fenn> ok so of the things kagi listed, only #1 (unknown intracellular molecular memory) and #5 (RNA-based memory) are not secretly actually synaptic memory encoding
04:36 < fenn> one could hypothetically attach a reporter sequence for these things to the DNA barcode before it's exported, but we'd have to discover it first. frankly i find it hard to believe that such things exist and are important to behavior but still haven't been discovered
04:36 < fenn> s/it/them/
04:37 < hprmbridge> kanzure> there's also one about extracellular matrix vacancies or something
04:37 < hprmbridge> kanzure> "perineuronal net" swiss cheese theory
04:37 < fenn> there's no room for extracellular matrix, it's jam packed full of neurons
04:38 < fenn> god of the gaps theory
04:43 < hprmbridge> kanzure> what if it's protein conformational states or mechanical compressions
04:43 < fenn> ok so PNNs are a structural reinforcement layer that can "fossilize" a pre-existing synaptic connection, making a memory that would have been forgotten or desensitized become permanent instead
04:51 < fenn> i wish they didn't call it a "net" which is needlessly confusing
04:53 < fenn> alright i concede that PNNs could be important for imprinted personality traits that people would find important and part of their identity
04:57 < kanzure> obvious solution is neural network quines that predict their own weights
04:57 < kanzure> and then you have substrate independence
04:58 < kanzure> relying on a system that has high-resolution details beyond your best optical/scanning capabilities seems unwise!
...
05:03 < fenn> .t https://pmc.ncbi.nlm.nih.gov/articles/PMC3725115/
05:03 < saxo> Very long-term memories may be stored in the pattern of holes in the perineuronal net - PMC
```

I would like to somehow encourage people to dream even bigger and more ambitiously about how to solve these problems. To solve problems we have never solved before, we need completely different ideas and approaches. So much thinking in neuro is stunted by psychology self-conception issues - it's very hard to detach and really think about these alien systems without resorting to "folk neuroscience" or "folk psychology".


ref- private correspondence, REDACTED, neurobiology professor

