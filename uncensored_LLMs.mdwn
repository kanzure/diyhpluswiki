Some uncensored LLMs:

<https://huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera>

Dolphin org:

* <https://huggingface.co/dphn>
* <https://dphn.ai/> <https://x.com/dphnAI> <https://t.me/dphnAI>
* Eric Hartford <https://huggingface.co/ehartford> <https://x.com/cognitivecompai>
* <https://huggingface.co/dphn/Dolphin-Mistral-24B-Venice-Edition>
* [Dolphin X1 405b](https://blog.dphn.ai/405b/) 

Jinx-org:

* <https://huggingface.co/Jeol> <https://opdoop.github.io/>
* <https://huggingface.co/VivianKeith>
* <https://huggingface.co/Jinx-org/Jinx-Qwen3-235B-A22B-Thinking-2507>
* <https://huggingface.co/Jinx-org/Jinx-gpt-oss-20b>

<https://github.com/jim-plus/llm-abliteration/>

<https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard> with "Uncensored" category.

<https://lobotomyq.com/> The Lobotomy Quotient ; Quantifying censorship levels across leading language models. Lower scores indicate more intact responses, higher scores reflect increased content filtering. but only 7 models benchmarked.

[Safety tax: Safety alignment makes your large reasoning models less reasonable](https://arxiv.org/abs/2503.00555)

[Jinx: Unlimited LLMs for probing alignment failures](https://arxiv.org/abs/2508.08243)


